---
id: c025ef1c-d50d-45f7-b2ea-c30a94baa434
discussion: <discord url>
learning-outcome: Participants can explain why the author treats misalignment and catastrophe as default outcomes under current training paradigms, and can propose concrete examples of “fundamental advances” in security theory or alignment science that would update them toward believing deployment can be safe, stating what would be proved, measured, or guaranteed, and what failure modes this would rule out.
tags:
  - work-in-progress
  - learning outcome
---
## Test:

## Lens:
optional:: true
source:: [[../Lenses/Without fundamental advances, misalignment and catastrophe are the default outcomes of training powerful AIst outcomes]]