---
id: 60a1046d-cb9d-4803-ac84-810e070b79fb
tags :
  - lens
  - work-in-progress
---
### Article: Discovering when an agent is present in a system by Zachary Kenton et al.
source:: [[../articles/]]

#### Text
content::
In AI safety we often model systems as agents, meaning systems that make decisions to achieve objectives. But this can be a modelling choice rather than an obvious fact. This post proposes a causal definition of agency grounded in how the system’s behaviour would change under specific counterfactual changes in how its actions affect the world. The core idea is: an agent is a system that would adapt its policy if the causal influence of its actions were different, and we can in principle test for this using intervention style data and causal modelling tools such as causal influence diagrams.


#### Article-excerpt
to:: "`<an exact quote from the article where the exerpt should stop>`"

#### Text
content::
What new things did you learn from the article?

#### Chat: Discussion on X-Risk
instructions::
TLDR of what the user just read:
`<TLDR text (optional, the bot can see all the text on the page)>`

Discussion topics to explore:
- `<Discussion point 1>`
- `<Discussion point 2>`
- `<Discussion point 3>`
- `<Discussion point 4>`

Ask what they found surprising or new. Check if they can explain `<key concept>` in their own words—it's a key concept.

The user just answered the question: `<tell the chatbot what prompt the user is responding to>`